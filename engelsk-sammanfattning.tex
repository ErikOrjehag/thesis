Perception of depth, ego motion and robust keypoints is critical for SLAM and structure from motion applications. Neural networks have achieved great performance in perception tasks in recent years. But collecting labeled data for supervised training is labor intensive and costly. This thesis explores recent methods in unsupervised training of neural networks that can predict depth, ego motion, keypoints and do geometric consensus maximization. The benefit from unsupervised training is that the networks can learn from raw data collected from the camera sensor, as oppose to labeled data. The thesis focuses on training on images from a monocular camera, where no stereo or LIDAR data is available. The experiments compare different techniques for depth and ego motion prediction from previous research, and shows how the techniques can be combined successfully. A keypoint prediction network is evaluated and its performance is compared with the ORB detector provided by OpenCV. A geometric consensus network is also implemented and its performance is compared with the RANSAC algorithm in OpenCV. The consensus maximization network is trained on the output of the keypoint prediction network. For future work it is suggested that all networks could be combined and trained jointly to reach a better overall performance. The results show (1) which techniques in unsupervised depth prediction are most effective, (2) that the keypoint predicting network outperformed the ORB detector, and (3) that the consensus maximization network was able to classify outliers with comparable performance to the RANSAC algorithm of OpenCV.
