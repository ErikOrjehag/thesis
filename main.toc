\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\contentsline {chapter}{Notation}{ix}{section*.5}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Research Questions}{2}{section.1.2}
\contentsline {section}{\numberline {1.3}Delimitations}{2}{section.1.3}
\contentsline {chapter}{\numberline {2}Background}{3}{chapter.2}
\contentsline {section}{\numberline {2.1}Convolutional neural networks and learning}{3}{section.2.1}
\contentsline {chapter}{\numberline {3}Related work}{5}{chapter.3}
\contentsline {section}{\numberline {3.1}Unsupervised Monocular Depth Estimation with Left-Right Consistency}{5}{section.3.1}
\contentsline {section}{\numberline {3.2}Unsupervised Learning of Depth and Ego-Motion from Video}{6}{section.3.2}
\contentsline {section}{\numberline {3.3}SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation}{7}{section.3.3}
\contentsline {section}{\numberline {3.4}3D Packing for Self-Supervised Monocular Depth Estimation}{7}{section.3.4}
\contentsline {section}{\numberline {3.5}Digging Into Self-Supervised Monocular Depth Estimation}{7}{section.3.5}
\contentsline {section}{\numberline {3.6}Self-Supervised 3D Keypoint Learning for Ego-motion Estimation}{8}{section.3.6}
\contentsline {section}{\numberline {3.7}UnsuperPoint: End-To-End Unsupervised Interest Point Detector and Descriptor}{8}{section.3.7}
\contentsline {section}{\numberline {3.8}Unsupervised Learning of Consensus Maximization for 3D Vision Problems}{8}{section.3.8}
\contentsline {chapter}{\numberline {4}Method}{9}{chapter.4}
\contentsline {section}{\numberline {4.1}Sequence datasets}{9}{section.4.1}
\contentsline {section}{\numberline {4.2}Homography dataset}{10}{section.4.2}
\contentsline {section}{\numberline {4.3}Combining techniques from previous research}{10}{section.4.3}
\contentsline {section}{\numberline {4.4}Evaluation metrics}{10}{section.4.4}
\contentsline {subsection}{\numberline {4.4.1}Depth error and accuracy metrics}{10}{subsection.4.4.1}
\contentsline {subsection}{\numberline {4.4.2}Camera ego motion error metric}{12}{subsection.4.4.2}
\contentsline {subsection}{\numberline {4.4.3}Keypoint error and score metrics}{12}{subsection.4.4.3}
\contentsline {subsection}{\numberline {4.4.4}Consensus maximization performance metrics}{13}{subsection.4.4.4}
\contentsline {chapter}{\numberline {5}Implementation}{15}{chapter.5}
\contentsline {subsection}{\numberline {5.0.1}Architectures for depth and ego motion CNNs}{15}{subsection.5.0.1}
\contentsline {subsection}{\numberline {5.0.2}Differentiable depth image warping}{16}{subsection.5.0.2}
\contentsline {subsection}{\numberline {5.0.3}Loss functions}{17}{subsection.5.0.3}
\contentsline {subsection}{\numberline {5.0.4}Handling occlusions}{19}{subsection.5.0.4}
\contentsline {subsection}{\numberline {5.0.5}Handling model limitations}{20}{subsection.5.0.5}
\contentsline {paragraph}{Explainability mask}{20}{section*.15}
\contentsline {paragraph}{Stationary pixels mask}{21}{section*.16}
\contentsline {section}{\numberline {5.1}Unsupervised keypoint learning}{22}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Loss function for keypoint learning}{24}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}Generating random homographies}{24}{subsection.5.1.2}
\contentsline {section}{\numberline {5.2}Unsupervised consensus maximization}{25}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Improving training convergence}{29}{subsection.5.2.1}
\contentsline {chapter}{\numberline {6}Results}{31}{chapter.6}
\contentsline {section}{\numberline {6.1}Depth and ego motion}{32}{section.6.1}
\contentsline {section}{\numberline {6.2}Keypoint detection}{35}{section.6.2}
\contentsline {section}{\numberline {6.3}Consensus maximization}{36}{section.6.3}
\contentsline {chapter}{\numberline {7}Discussion}{39}{chapter.7}
\contentsline {section}{\numberline {7.1}Results}{39}{section.7.1}
\contentsline {section}{\numberline {7.2}Method}{39}{section.7.2}
\contentsline {section}{\numberline {7.3}The work in a wider context}{39}{section.7.3}
\contentsline {chapter}{\numberline {8}Conclusions}{41}{chapter.8}
\contentsline {paragraph}{\textbf {How well do the unsupervised methods from previous research work on new datasets not tested in the original papers?}}{41}{section*.32}
\contentsline {paragraph}{\textbf {What are the performance gains of combining different methods from recent research in monocular depth and ego motion prediction?}}{41}{section*.33}
\contentsline {section}{\numberline {8.1}Future work}{41}{section.8.1}
\contentsline {chapter}{Bibliography}{43}{chapter*.34}
