\chapter{Introduction}\label{cha:introduction}

This thesis aims to show how new neural network techniques can be used to predict depth and relative camera motion for an image sequence captured by a monocular \abbrRGB camera. Imagine closing one eye and looking out into the world, it is trivial as a grownup human to detect motion and estimate how the head moves in relation to what is seen. Calculating camera movement from an image sequence is a well studied problem and is usually done by finding corresponding features in the images and calculating (using projective geometry) which camera movement can give rise to such correspondences and their relative movement between frames in the sequence.

Recent research has shown that it's possible to predict depth and relative motion from a sequence of images taken with a monocular \abbrRGB camera, up to a unknown scale factor. The training data is a sequence of unlabeled images with a small relative motion, for example looking out from the front window of a moving car. Given a target view and a new nearby view it's possible to train depth and pose predicting \abbrCNN{}s jointly using a combined loss function. The depth and pose predictions are used to warp nearby views to the target view and the loss is based on the similarity achieved after warping.

\section{Motivation}

Here are three main points motivating future research into the use of unsupervised learning methods for visual structure from motion.


\begin{itemize}
	\item Localization of autonomous vehicles is commonly  achieved using lidar sensors due to their high accuracy and robustness, but using cameras instead comes with many other benefits. For example lower hardware cost and power consumption. Cameras are passive sensors which means that they don't interfere with each other. Lidars rely on spinning parts which can break if subjected to shaking or impact. Focusing on monoscopic vision instead of stereo vision again comes down to cost benefits.
	
	\item Obtaining labeled data for supervised training can be a tedious task, in that respect unsupervised methods are much more desirable. Labeling data is time consuming, expensive and prone to human errors. Collecting and storing data without labeling it is however comparably easy and inexpensive.
	
	\item This thesis focuses on depth, ego motion, keypoint prediction and consensus maximization. The motivation for this choice of unsupervised methods is the idea that in future work it might be possible to combine these methods to jointly learn all the tasks at the same time where each part of the system benefits from the others during training. The hope would be that the performance of the system would increase simply by collecting more unlabeled data.
\end{itemize}

\section{Research Questions}

\begin{enumerate}
	
	\item How well do the unsupervised methods from previous research work on new datasets not tested in the original papers?
	
	\item What are the performance gains of combining different methods from recent research in monocular depth and ego motion prediction?
	
\end{enumerate}

\section{Delimitations}

The visual localization problem can be solved using, for example, a stereoscopic camera or a time of flight camera. But this thesis will only explore the use of a monoscopic, non depth sensing, \abbrRGB camera, because it enables applications where hardware cost is a big factor.

In a full \abbrSFM pipeline, both 3D-reconstruction, bundle adjustment and loop-closure detection are usually done as well. This will not be part of this thesis project.